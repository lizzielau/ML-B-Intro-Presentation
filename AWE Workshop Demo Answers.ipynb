{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "We are going to build a convolutional neural network to predict image classes on CIFAR-10, a dataset of images of 10 different things (i.e. 10 classes). Things like airplanes, cars, deer, horses, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Load the cifar10 dataset from Keras. If you need a hint go to [Keras Datasets](https://keras.io/datasets). This might take a little while to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(cifar_x_train, cifar_y_train), (cifar_x_test, cifar_y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Cifar Translations\n",
    "cifar_dict = {\n",
    "    0: \"plane\",\n",
    "    1:\"car\",\n",
    "    2:\"bird\",\n",
    "    3:\"cat\",\n",
    "    4:\"deer\",\n",
    "    5:\"dog\",\n",
    "    6:\"frog\",\n",
    "    7:\"horse\",\n",
    "    8:\"ship\",\n",
    "    9:\"truck\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Initialize a Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Add a ``Conv2D`` layer to the model. It should have 32 filters, a 5x5 kernel, and a 1x1 stride. The documentation [here](https://keras.io/layers/convolutional/#conv2d) will be your friend for this problem. __Hint:__ This is the first layer of the model so you have to specify the input shape. I recommend printing ``cifar_x_train.shape``, to get an idea of what the shape of the data looks like. Then add a ```relu``` activation layer to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Activation\n",
    "print(cifar_x_train.shape)\n",
    "##YOUR CODE HERE\n",
    "\n",
    "cifar_model.add(Conv2D(32, (5,5), input_shape=(32,32,3)))\n",
    "cifar_model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Add a ``MaxPooling2D`` layer to the model. The layer should have a 2x2 pool size. The documentation for Max Pooling is [here](https://keras.io/layers/pooling/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.pooling import MaxPooling2D\n",
    "##YOUR CODE HERE\n",
    "\n",
    "cifar_model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Add another ``Conv2D`` identical to last one, then another ``relu`` activation, then another ``MaxPooling2D`` layer. __Hint:__ You've already written this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##YOUR CODE HERE\n",
    "\n",
    "cifar_model.add(Conv2D(32, (5,5)))\n",
    "cifar_model.add(Activation('relu'))\n",
    "cifar_model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** Add another ``Conv2D`` layer identical to the others except with 64 filters instead of 32. Add another ``relu`` activation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##YOUR CODE HERE\n",
    "\n",
    "cifar_model.add(Conv2D(64, (5,5)))\n",
    "cifar_model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(g)** Now we want to move from 2D data to 1D vectors for classification, to this we have to flatten the data. Keras has a layer for this called [Flatten](https://keras.io/layers/core/#flatten). Then add a ``Dense`` (fully connected) layer with 64 neurons, a ``relu`` activation layer, another ``Dense`` layer with 10 neurons, and a ``softmax`` activation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "##YOUR CODE HERE\n",
    "\n",
    "cifar_model.add(Flatten())\n",
    "cifar_model.add(Dense(64))\n",
    "cifar_model.add(Activation('relu'))\n",
    "cifar_model.add(Dense(10))\n",
    "cifar_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have constructed a network that takes in an image and outputs a vector of 10 numbers and then we take the softmax of these, which leaves us with a vector of 0s except 1 one and the location of this one in the vector corresponds to which class the network is predicting for that image. This is sort of the canonical way of doing image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(h)** Now print a summary of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 10, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 1, 64)          51264     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 84,138\n",
      "Trainable params: 84,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##YOUR CODE HERE\n",
    "\n",
    "cifar_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(i)** We need to convert our labels from integers to length 10 vectors with 9 zeros and 1 one, where the integer label is the index of the 1 in the vector. Luckily, Keras has a handy function to do this for us. Have a look [here](https://keras.io/utils/#to_categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_cat = to_categorical(cifar_y_train)\n",
    "y_test_cat = to_categorical(cifar_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(j)** Now compile the model with SGD optimizer and categorical_crossentropy loss function and also include ``metrics=['accuracy']`` as a parameter so we can see the accuracy of the model. Then train the model on the training data. For training we want to weight the classes in the loss function, so set the ``class_weight`` parameter of fit to be the ``class_weights`` dictionary. Be warned training can take forever, I trained on a cpu for 20 epochs (about 30 minutes) and only got 20% accuracy. For the purposes of this assignment, you don't need to worry to much about accuracy, just train for at least 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##YOUR COMPILING CODE HERE\n",
    "\n",
    "cifar_model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anacismaru/anaconda3/envs/nmep/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.0014 - accuracy: 0.1104\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 7.7821e-04 - accuracy: 0.1325\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 5.8924e-04 - accuracy: 0.1443\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 5.3754e-04 - accuracy: 0.1523\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 5.0921e-04 - accuracy: 0.1605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f97a946fa58>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = {}\n",
    "for i in range(10):\n",
    "    class_weights[i] = 1. / np.where(cifar_y_train==i)[0].size\n",
    "\n",
    "##YOUR TRAINING CODE HERE\n",
    "\n",
    "cifar_model.fit(cifar_x_train, y_train_cat, class_weight=class_weights, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 296us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5048769306182863, 0.1687999963760376]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_model.evaluate(cifar_x_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the class labels the network predicts on our test set and look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label:  horse\n",
      "True label:  car\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = cifar_model.predict(cifar_x_test)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(cifar_x_test[1234])\n",
    "print(\"Predicted label: \", cifar_dict[np.argmax(y_pred[1234])])\n",
    "print(\"True label: \", cifar_dict[cifar_y_test[1234][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "nmep",
   "language": "python",
   "name": "nmep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
